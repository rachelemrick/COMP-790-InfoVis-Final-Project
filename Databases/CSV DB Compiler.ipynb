{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "325bd065-969b-4c08-ad2a-397fb81ef30d",
   "metadata": {},
   "source": [
    "This notebook will allow us to experiment with editing CSV files and hopefully eventually allow us to combine them. Python has a built-in CSV library we can use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cefb56e-0b7d-43f5-b51a-912fe4364df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no. of rows: 1513\n",
      "Field names are:, Title, Release Date, Team, Rating, Times Listed, Number of Reviews, Genres, Plays, Playing, Backlogs, Wishlist\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "filename = \"popular-games-no-reviews.csv\"\n",
    "\n",
    "# Starter code from https://www.geeksforgeeks.org/working-csv-files-python/#\n",
    "# initializing the titles and rows list\n",
    "original_fields = []\n",
    "original_rows = []\n",
    " \n",
    "# reading csv file\n",
    "with open(filename, 'r', encoding='Latin1') as csvfile:\n",
    "    # creating a csv reader object\n",
    "    csvreader = csv.reader(csvfile)\n",
    " \n",
    "    # extracting field names through first row\n",
    "    original_fields = next(csvreader)\n",
    " \n",
    "    # extracting each data row one by one\n",
    "    for row in csvreader:\n",
    "        # Only add if the game has been released\n",
    "        if row[2] != \"releases on TBD\":\n",
    "            original_rows.append(row)\n",
    " \n",
    "    # get total number of rows\n",
    "    print(\"Total no. of rows: %d\" % (csvreader.line_num))\n",
    " \n",
    "# printing the field names\n",
    "print('Field names are:' + ', '.join(field for field in original_fields))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0a1f8b-215c-4d79-9961-dc4ceee340bf",
   "metadata": {},
   "source": [
    "So now we have the list of rows stored in the variable \"rows\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e47b35c6-a31d-45d5-81de-415c11be7c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0', 'Elden Ring', '25-Feb-22', \"['Bandai Namco Entertainment', 'FromSoftware']\", '4.5', '3.9K', '3.9K', \"['Adventure', 'RPG']\", '17K', '3.8K', '4.6K', '4.8K'], ['1', 'Hades', '10-Dec-19', \"['Supergiant Games']\", '4.3', '2.9K', '2.9K', \"['Adventure', 'Brawler', 'Indie', 'RPG']\", '21K', '3.2K', '6.3K', '3.6K'], ['2', 'The Legend of Zelda: Breath of the Wild', '3-Mar-17', \"['Nintendo', 'Nintendo EPD Production Group No. 3']\", '4.4', '4.3K', '4.3K', \"['Adventure', 'RPG']\", '30K', '2.5K', '5K', '2.6K'], ['3', 'Undertale', '15-Sep-15', \"['tobyfox', '8-4']\", '4.2', '3.5K', '3.5K', \"['Adventure', 'Indie', 'RPG', 'Turn Based Strategy']\", '28K', '679', '4.9K', '1.8K'], ['4', 'Hollow Knight', '24-Feb-17', \"['Team Cherry']\", '4.4', '3K', '3K', \"['Adventure', 'Indie', 'Platform']\", '21K', '2.4K', '8.3K', '2.3K']]\n"
     ]
    }
   ],
   "source": [
    "print(original_rows[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c33ebf4d-7d83-4eea-a6c1-cfcc5465004a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undertale\n",
      "['Adventure', 'Indie', 'RPG', 'Turn Based Strategy']\n"
     ]
    }
   ],
   "source": [
    "# These constants correspond to the index of the field\n",
    "TITLE = 1\n",
    "RELEASE_DATE = 2\n",
    "TEAM = 3\n",
    "RATING = 4\n",
    "TIMES_LISTED = 5\n",
    "NUMBER_OF_REVIEWS = 6\n",
    "GENRES = 7\n",
    "PLAYS = 8\n",
    "PLAYING = 9\n",
    "BACKLOGS = 10\n",
    "WISHLIST = 11\n",
    "\n",
    "print(original_rows[3][TITLE])\n",
    "print(original_rows[3][GENRES])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec93b6d8-6d70-45bf-aea3-6098ccc84289",
   "metadata": {},
   "source": [
    "Next, create the new fields that we want to add to. Don't run the cell directly below this more than once!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc5d7012-65a5-467e-87e0-218ebbfad431",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVELOPER = 12\n",
    "PUBLISHER = 13\n",
    "\n",
    "original_fields.append(\"Developer\")\n",
    "original_fields.append(\"Publisher\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fc514bb-17f3-4b3b-9683-6e61c9b314e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no. of rows: 64006\n",
      "Field names are:name, date, platform, publisher, developer, shipped, total, america, europe, japan, other, vgc, critic, user\n"
     ]
    }
   ],
   "source": [
    "# Read in VGChartz DB. Do it with a dictionary this time!\n",
    "# initializing the titles and rows list\n",
    "VGCHARTZ_NAME = 0\n",
    "VGCHARTZ_DATE = 1\n",
    "VGCHARTZ_PUBLISHER = 3\n",
    "VGCHARTZ_DEVELOPER = 4\n",
    "VGCHARTZ_SHIPPED = 5\n",
    "\n",
    "vgchartz_fields = []\n",
    "vgchartz_rows = []\n",
    "vgchartz_dict = {}    # store TITLE -> INDEX, so that we can quickly find the correct row for any given game.\n",
    "                      # We must use lists, because multiple games may be published under the same name (e.g. Tetris).\n",
    "\n",
    "# reading csv file\n",
    "with open(\"vgchartz.csv\", 'r', encoding='Latin1') as csvfile:\n",
    "    # creating a csv reader object\n",
    "    csvreader = csv.reader(csvfile)\n",
    " \n",
    "    # extracting field names through first row\n",
    "    vgchartz_fields = next(csvreader)\n",
    " \n",
    "    # extracting each data row one by one\n",
    "    index = 0\n",
    "    for row in csvreader:\n",
    "        vgchartz_rows.append(row)\n",
    "        # Next, take care of the dictionary\n",
    "        if row[VGCHARTZ_NAME] in vgchartz_dict:\n",
    "            # If there already is a value here, append the new value to the list\n",
    "            vgchartz_dict[row[VGCHARTZ_NAME]].append(index)\n",
    "        else:\n",
    "            # If there isn't a value here yet, create a list for the dictionary\n",
    "            vgchartz_dict[row[VGCHARTZ_NAME]] = [index]\n",
    "            \n",
    "        index += 1\n",
    " \n",
    "    # get total number of rows\n",
    "    print(\"Total no. of rows: %d\" % (csvreader.line_num))\n",
    " \n",
    "# printing the field names\n",
    "print('Field names are:' + ', '.join(field for field in vgchartz_fields))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1005dee-f853-436c-b25f-d0615e1d4148",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 92, 693, 49762, 49763]\n"
     ]
    }
   ],
   "source": [
    "# Test cases\n",
    "print(vgchartz_dict[\"Tetris\"]) # This means that rows 0, 92, 693, 49762, and 49763 contain versions of Tetris\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6626af9a-37a6-40b9-97e0-027157939466",
   "metadata": {},
   "source": [
    "Fill out the new fields. We can do that by looping through original_rows and extracting data from vgchartz_rows using vgchartz_dict for each entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1510d413-eb0e-4c70-bb48-f009cb1bc7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "RELEASE_YEAR = 14\n",
    "RELEASE_MONTH = 15\n",
    "\n",
    "original_fields.append(\"Year Released\")\n",
    "original_fields.append(\"Month Released\")\n",
    "\n",
    "for row in original_rows:\n",
    "    # First, find the corresponding entry in vgchartz\n",
    "    title = row[TITLE]\n",
    "    date = row[RELEASE_DATE]\n",
    "    true_year = date[-2:]    # in format e.g. \"17\" or \"23\"\n",
    "\n",
    "    # Check that it exists\n",
    "    if title in vgchartz_dict:\n",
    "        # Once we get here, there is at least one entry in vgchartz for this title\n",
    "        possible_vgchartz_indices = vgchartz_dict[title]\n",
    "        pub = None\n",
    "        dev = None\n",
    "\n",
    "        # Pick out which of the possible indices is the correct one using the release date\n",
    "        true_index = possible_vgchartz_indices\n",
    "        found_info = False\n",
    "        for index in possible_vgchartz_indices:\n",
    "            possible_year = vgchartz_rows[index][VGCHARTZ_DATE][2:4]\n",
    "\n",
    "            # If possible year is the same as true year, assume these are the same games. Also, don't overwrite, in case of repeat entries,\n",
    "            # assume the higher index is the better one\n",
    "            if possible_year == true_year and not found_info:\n",
    "                pub = vgchartz_rows[index][VGCHARTZ_PUBLISHER]\n",
    "                dev = vgchartz_rows[index][VGCHARTZ_DEVELOPER]\n",
    "                # shipped = vgchartz_rows[index][VGCHARTZ_SHIPPED]\n",
    "                found_info = True\n",
    "    \n",
    "        # Append the correct developer, publisher, shipped information as found from vgchartz\n",
    "        row.append(dev)\n",
    "        row.append(pub)\n",
    "        # row.append(shipped)\n",
    "        \n",
    "    else:\n",
    "        # There was no entry in vgchartz for this title, so we have no publisher/developer data\n",
    "        row.append(None)    # TODO: this might not be the right syntax for an empty entry, double check this\n",
    "        row.append(None)\n",
    "        # row.append(None)\n",
    "\n",
    "    # While we have the true year picked out, add release year and release month as their own columns\n",
    "    if int(true_year) < 25:\n",
    "        row.append(\"20\" + true_year)\n",
    "    else:\n",
    "        row.append(\"19\" + true_year)\n",
    "    row.append(date.split(\"-\")[1])\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa33a19f-7c3b-4839-a300-257967155ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elden Ring\n",
      "['Bandai Namco Entertainment', 'FromSoftware']\n",
      "From Software\n",
      "Bandai Namco Entertainment\n",
      "\n",
      "Hades\n",
      "['Supergiant Games']\n",
      "None\n",
      "None\n",
      "\n",
      "The Legend of Zelda: Breath of the Wild\n",
      "['Nintendo', 'Nintendo EPD Production Group No. 3']\n",
      "Nintendo\n",
      "Nintendo\n",
      "\n",
      "Undertale\n",
      "['tobyfox', '8-4']\n",
      "Toby Fox\n",
      "Toby Fox\n",
      "\n",
      "Hollow Knight\n",
      "['Team Cherry']\n",
      "Team Cherry\n",
      "Team Cherry\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check that the above code worked by printing some examples\n",
    "i = 0\n",
    "while i < 5:  \n",
    "    print(original_rows[i][TITLE])\n",
    "    print(original_rows[i][TEAM])\n",
    "    print(original_rows[i][DEVELOPER])\n",
    "    print(original_rows[i][PUBLISHER])\n",
    "    print()\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f059ca7d-a09d-4aea-b925-ec377a1af298",
   "metadata": {},
   "source": [
    "Now the entries of publisher and developer sometimes give redundant indoemation from the team entries, but sometimes they're written in a format that might be more helpful (e.g. Toby Fox vs. the stylized tobyfox).\n",
    "\n",
    "Next, consider how to label indie vs. non-indie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c8b3b8d-3dc7-4414-889c-aafc3bf3217a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Coffee Stain': <Game_type.INDIE: 2>, 'Paradox': <Game_type.INDIE: 2>, 'Focus Entertainment': <Game_type.AAA: 1>, '505 Games': <Game_type.INDIE: 2>, 'Team17': <Game_type.AAA: 1>, 'Devolver': <Game_type.INDIE: 2>, 'Curve Games': <Game_type.INDIE: 2>, 'tinyBuild': <Game_type.INDIE: 2>, 'Humble Games': <Game_type.INDIE: 2>, 'Funcom': <Game_type.INDIE: 2>, 'Private Division': <Game_type.INDIE: 2>, '11 bit studios': <Game_type.INDIE: 2>, 'Square Enix Collective': <Game_type.INDIE: 2>, 'Behaviour Interactive': <Game_type.INDIE: 2>, 'Tripwire Interactive': <Game_type.INDIE: 2>, 'Annapurna Interactive': <Game_type.INDIE: 2>, 'PlayWay': <Game_type.INDIE: 2>, 'XSEED Games': <Game_type.INDIE: 2>, 'Starbreeze': <Game_type.INDIE: 2>, 'Thunderful Games': <Game_type.INDIE: 2>, 'Dear Villagers': <Game_type.INDIE: 2>, 'Twin Sails Interactive': <Game_type.INDIE: 2>, 'Dotemu': <Game_type.INDIE: 2>, '3D Realms': <Game_type.INDIE: 2>, 'Hooded Horse': <Game_type.INDIE: 2>, 'Paradox Arc': <Game_type.INDIE: 2>, 'Modern Wolf': <Game_type.INDIE: 2>, 'Secret Mode': <Game_type.INDIE: 2>, 'Chucklefish': <Game_type.INDIE: 2>, 'Crytivo': <Game_type.INDIE: 2>, 'Raw Fury': <Game_type.INDIE: 2>, 'Merge Games': <Game_type.INDIE: 2>, 'Wired Productions': <Game_type.INDIE: 2>, 'Fellow Traveller': <Game_type.INDIE: 2>, 'Irregular Corporation': <Game_type.INDIE: 2>, 'My.Games': <Game_type.INDIE: 2>, 'Microids': <Game_type.INDIE: 2>, 'GameForge': <Game_type.INDIE: 2>, 'Ultimate Games S.A': <Game_type.INDIE: 2>, 'Slitherine': <Game_type.INDIE: 2>, 'Shiro Unlimited': <Game_type.INDIE: 2>, 'Headup': <Game_type.INDIE: 2>, 'Wales Interactive': <Game_type.INDIE: 2>, 'Panic': <Game_type.INDIE: 2>, 'Kitfox Games': <Game_type.INDIE: 2>, 'Goblinz Publishing': <Game_type.INDIE: 2>, 'Fireshine Games': <Game_type.INDIE: 2>, 'Maximum Entertainment': <Game_type.INDIE: 2>, 'Handy Games': <Game_type.INDIE: 2>, 'Deck13 Spotlight': <Game_type.INDIE: 2>, 'Dangen Entertainment': <Game_type.INDIE: 2>, 'Freedom Games': <Game_type.INDIE: 2>, 'Playstack': <Game_type.INDIE: 2>, 'Armor Games Studio': <Game_type.INDIE: 2>, 'Skystone': <Game_type.INDIE: 2>, 'Double Eleven': <Game_type.INDIE: 2>, 'Games Operators': <Game_type.INDIE: 2>, 'All iN! Games': <Game_type.INDIE: 2>, 'Excalibur Games': <Game_type.INDIE: 2>, 'Kasedo Games': <Game_type.INDIE: 2>, 'Firesquid': <Game_type.INDIE: 2>, 'Blowfish Studios': <Game_type.INDIE: 2>, 'Herocraft': <Game_type.INDIE: 2>, 'Big Cheese Studio': <Game_type.INDIE: 2>, 'The Arcade Crew': <Game_type.INDIE: 2>, 'United Label': <Game_type.INDIE: 2>, 'Ishtar Games': <Game_type.INDIE: 2>, 'SOEDESCO': <Game_type.INDIE: 2>, 'Iceberg Interactive': <Game_type.INDIE: 2>, 'Green Man Gaming': <Game_type.INDIE: 2>, 'Assemble Entertainment': <Game_type.INDIE: 2>, 'Outright Games': <Game_type.INDIE: 2>, 'H2 Interactive': <Game_type.INDIE: 2>, 'Klabater': <Game_type.INDIE: 2>, 'Toge Productions': <Game_type.INDIE: 2>, 'Pixmain': <Game_type.INDIE: 2>, 'Whitethorn Games': <Game_type.INDIE: 2>, 'Those Awesome Guys': <Game_type.INDIE: 2>, 'Indie Ark': <Game_type.INDIE: 2>, 'Daedalic Entertainment': <Game_type.INDIE: 2>, 'Whisper Games': <Game_type.INDIE: 2>, 'Gamera Games': <Game_type.INDIE: 2>, 'Serenity Forge': <Game_type.INDIE: 2>, 'Gearbox Publishing': <Game_type.AAA: 1>, 'Meta Publishing': <Game_type.INDIE: 2>, 'Ravenage Games': <Game_type.INDIE: 2>, 'ARTE': <Game_type.INDIE: 2>, 'PQube': <Game_type.INDIE: 2>, 'DreadXP ': <Game_type.INDIE: 2>, 'Playdigious Originals': <Game_type.INDIE: 2>, 'Fulqrum Publishing': <Game_type.INDIE: 2>, '2P Games': <Game_type.INDIE: 2>, 'Untold Tales': <Game_type.INDIE: 2>, '101XP': <Game_type.INDIE: 2>, 'RockGame': <Game_type.INDIE: 2>, 'HypeTrain Digital': <Game_type.INDIE: 2>, 'Akupara Games': <Game_type.INDIE: 2>, 'Yogscast Games': <Game_type.INDIE: 2>, 'Playtonic': <Game_type.INDIE: 2>, 'FireStoke': <Game_type.INDIE: 2>, 'PID Games': <Game_type.INDIE: 2>, 'Mode7': <Game_type.INDIE: 2>, 'Walkabout Games': <Game_type.INDIE: 2>, 'Crunching Koalas': <Game_type.INDIE: 2>, 'Super Rare Originals': <Game_type.INDIE: 2>, 'Brace Yourself Games': <Game_type.INDIE: 2>, 'Digerati': <Game_type.INDIE: 2>, 'Big Sugar Games': <Game_type.INDIE: 2>, 'Graffiti Games': <Game_type.INDIE: 2>, 'No More Robots': <Game_type.INDIE: 2>, 'NoodleCake Games': <Game_type.INDIE: 2>, 'Bonus Stage Publishing': <Game_type.INDIE: 2>, 'Tribute Games': <Game_type.INDIE: 2>, 'Nordcurrent Labs': <Game_type.INDIE: 2>, 'Critical Reflex': <Game_type.INDIE: 2>, 'Forever Entertainment': <Game_type.INDIE: 2>, 'Top Hat Studios': <Game_type.INDIE: 2>, 'Roka Play': <Game_type.INDIE: 2>, 'Mooneye': <Game_type.INDIE: 2>, 'Grab the Games': <Game_type.INDIE: 2>, 'Dionous Games': <Game_type.INDIE: 2>, 'Different Tales': <Game_type.INDIE: 2>, 'Lesser Evil': <Game_type.INDIE: 2>, 'Static City Games': <Game_type.INDIE: 2>, 'Ancient Forge': <Game_type.INDIE: 2>, 'GIGATANK 3000': <Game_type.INDIE: 2>, 'Erabit Studios': <Game_type.INDIE: 2>, 'TAPBLAZE': <Game_type.INDIE: 2>, 'JanduSoft': <Game_type.INDIE: 2>, 'Smilegate': <Game_type.INDIE: 2>, 'Forklift Interactive': <Game_type.INDIE: 2>, 'Nejcraft': <Game_type.INDIE: 2>, 'Blue Sunset Games': <Game_type.INDIE: 2>, 'Entalto Studios': <Game_type.INDIE: 2>, 'Poysky Productions': <Game_type.INDIE: 2>, 'Gameforge': <Game_type.INDIE: 2>, '505 games': <Game_type.INDIE: 2>, 'Mojang': <Game_type.INDIE: 2>, 'Toby Fox': <Game_type.INDIE: 2>, 'Team Cherry': <Game_type.INDIE: 2>, 'Re-Logic': <Game_type.INDIE: 2>, 'Scott Cawthon': <Game_type.INDIE: 2>, 'Team 17': <Game_type.INDIE: 2>, 'Team Meat': <Game_type.INDIE: 2>, 'Matt Makes Games Inc.': <Game_type.INDIE: 2>, 'Yacht Club Games': <Game_type.INDIE: 2>, 'Campo Santo': <Game_type.INDIE: 2>, 'Supergiant Games': <Game_type.INDIE: 2>, 'Young Horses': <Game_type.INDIE: 2>, 'Polytron': <Game_type.INDIE: 2>, 'Robert Topala': <Game_type.INDIE: 2>, 'Night School Studio': <Game_type.INDIE: 2>, 'Facepalm Games': <Game_type.INDIE: 2>, 'Red Hook Studios': <Game_type.INDIE: 2>, 'Studio Pixel': <Game_type.INDIE: 2>, 'Endnight Games Ltd': <Game_type.INDIE: 2>, 'Starbreeze Studios': <Game_type.INDIE: 2>, 'iam8bit': <Game_type.INDIE: 2>, 'Studio MDHR': <Game_type.INDIE: 2>, 'Jumpship': <Game_type.INDIE: 2>, 'Pillow Castle': <Game_type.INDIE: 2>, 'Nicalis': <Game_type.INDIE: 2>, 'Sloclap': <Game_type.INDIE: 2>, 'Psyonix Studios': <Game_type.INDIE: 2>, 'Bedtime Digital Games': <Game_type.INDIE: 2>, 'Thomas Happ Games': <Game_type.INDIE: 2>, '3909 LLC': <Game_type.INDIE: 2>, 'Coffee Stain Studios': <Game_type.INDIE: 2>, 'WayForward Technologies': <Game_type.INDIE: 2>, 'Amanita Design': <Game_type.INDIE: 2>, 'name': <Game_type.AAA: 1>, 'Valve': <Game_type.AAA: 1>, 'KRAFTON, Inc.': <Game_type.AAA: 1>, 'Electronic Arts': <Game_type.AAA: 1>, 'Ubisoft': <Game_type.AAA: 1>, 'Bethesda Softworks': <Game_type.AAA: 1>, 'SEGA': <Game_type.AAA: 1>, 'Xbox Game Studios': <Game_type.AAA: 1>, 'Activision': <Game_type.AAA: 1>, 'Rockstar Games': <Game_type.AAA: 1>, 'Paradox Interactive': <Game_type.AAA: 1>, '2K': <Game_type.AAA: 1>, 'Feral Interactive (Mac)': <Game_type.AAA: 1>, 'Larian Studios': <Game_type.AAA: 1>, 'CAPCOM Co., Ltd.': <Game_type.AAA: 1>, 'CD PROJEKT RED': <Game_type.AAA: 1>, 'Bandai Namco Entertainment': <Game_type.AAA: 1>, 'Feral Interactive (Linux)': <Game_type.AAA: 1>, 'Square Enix': <Game_type.AAA: 1>, 'PlayStation PC LLC': <Game_type.AAA: 1>, 'Bungie': <Game_type.AAA: 1>, 'Aspyr (Mac)': <Game_type.AAA: 1>, 'Digital Extremes': <Game_type.AAA: 1>, 'Warner Bros. Games': <Game_type.AAA: 1>, 'Amazon Games': <Game_type.AAA: 1>, 'FromSoftware Inc.': <Game_type.AAA: 1>, 'Aspyr (Linux)': <Game_type.AAA: 1>, 'Pocketpair': <Game_type.AAA: 1>, 'Behaviour Interactive Inc.': <Game_type.AAA: 1>, 'BANDAI NAMCO Entertainment': <Game_type.AAA: 1>, 'Coffee Stain Publishing': <Game_type.AAA: 1>, 'Bohemia Interactive': <Game_type.AAA: 1>, 'KONAMI': <Game_type.AAA: 1>, 'Gaijin Network Ltd': <Game_type.AAA: 1>, 'Devolver Digital': <Game_type.AAA: 1>, 'Facepunch Studios': <Game_type.AAA: 1>, 'SCS Software': <Game_type.AAA: 1>, 'Snail Games USA': <Game_type.AAA: 1>, 'Wargaming Group Limited': <Game_type.AAA: 1>, 'Techland': <Game_type.AAA: 1>, 'Warner Bros. Interactive Entertainment': <Game_type.AAA: 1>, 'Frontier Developments': <Game_type.AAA: 1>, 'THQ Nordic': <Game_type.AAA: 1>, 'Studio Wildcard': <Game_type.AAA: 1>, 'KOEI TECMO GAMES CO., LTD.': <Game_type.AAA: 1>, 'NetEase Games Global': <Game_type.AAA: 1>, 'PlayWay S.A.': <Game_type.AAA: 1>, 'Hello Games': <Game_type.AAA: 1>, 'CD Projekt Red Studio': <Game_type.AAA: 1>, 'Konami Digital Entertainment': <Game_type.AAA: 1>, 'Sega': <Game_type.AAA: 1>, 'Capcom': <Game_type.AAA: 1>, 'Namco Bandai': <Game_type.AAA: 1>, 'Valve Corporation': <Game_type.AAA: 1>, 'Namco Bandai Games': <Game_type.AAA: 1>, '2K Games': <Game_type.AAA: 1>, 'Sony Computer Entertainment': <Game_type.AAA: 1>, 'Sony Interactive Entertainment': <Game_type.AAA: 1>, 'Nintendo': <Game_type.AAA: 1>, 'Sony Computer Entertainment America': <Game_type.AAA: 1>, 'Bandai Namco': <Game_type.AAA: 1>, 'Blizzard Entertainment': <Game_type.AAA: 1>, 'Konami': <Game_type.AAA: 1>, 'EA Sports': <Game_type.AAA: 1>, 'Warner Bros. Interactive': <Game_type.AAA: 1>, 'Microsoft Game Studios': <Game_type.AAA: 1>, 'Microsoft Studios': <Game_type.AAA: 1>, 'LucasArts': <Game_type.AAA: 1>, 'Atlus': <Game_type.AAA: 1>, 'Atari': <Game_type.AAA: 1>, 'Bandai': <Game_type.AAA: 1>, 'Bandai Namco Games': <Game_type.AAA: 1>, 'Namco': <Game_type.AAA: 1>, 'Valve Software': <Game_type.AAA: 1>, 'Hasbro Interactive': <Game_type.AAA: 1>}\n"
     ]
    }
   ],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class Game_type(Enum):\n",
    "    AAA = 1\n",
    "    INDIE = 2\n",
    "    UNKNOWN = 3\n",
    "\n",
    "\n",
    "# Create a dictionary that maps from the publisher list to publishing type: String -> Game_type\n",
    "publisher_type_dict = {}\n",
    "\n",
    "# reading curated publisher list csv\n",
    "with open(\"Seyed's Publisher Database - Publishers (curated).csv\", 'r', encoding='Latin1') as csvfile:\n",
    "    # creating a csv reader object\n",
    "    csvreader = csv.reader(csvfile)\n",
    " \n",
    "    # extracting each data row one by one\n",
    "    for row in csvreader:\n",
    "        publisher_type_dict[row[0]] = Game_type.INDIE\n",
    "\n",
    "# reading open publisher list csv\n",
    "with open(\"Seyed's Publisher Database - Publishers (open).csv\", 'r', encoding='Latin1') as csvfile:\n",
    "    # creating a csv reader object\n",
    "    csvreader = csv.reader(csvfile)\n",
    " \n",
    "    # extracting each data row one by one\n",
    "    for row in csvreader:\n",
    "        publisher_type_dict[row[0]] = Game_type.INDIE\n",
    "\n",
    "# Add our own publisher list\n",
    "with open(\"our-indie-publisher-list.csv\", 'r', encoding='utf8') as csvfile:\n",
    "    # creating a csv reader object\n",
    "    csvreader = csv.reader(csvfile)\n",
    " \n",
    "    # extracting each data row one by one\n",
    "    for row in csvreader:\n",
    "        publisher_type_dict[row[0]] = Game_type.INDIE\n",
    "        \n",
    "# Remove the demarcations used in the Seyed DBs\n",
    "publisher_type_dict.pop('')\n",
    "publisher_type_dict.pop('Publisher')\n",
    "publisher_type_dict.pop('HIGH BUDGET')\n",
    "publisher_type_dict.pop('MID BUDGET')\n",
    "publisher_type_dict.pop('LOW BUDGET')\n",
    "\n",
    "\n",
    "# Now add the list of AAA publishers\n",
    "# reading open publisher list csv\n",
    "with open(\"aaa-aa-publisher-list.csv\", 'r', encoding='Latin1') as csvfile:\n",
    "    # creating a csv reader object\n",
    "    csvreader = csv.reader(csvfile)\n",
    " \n",
    "    # extracting each data row one by one\n",
    "    for row in csvreader:\n",
    "        publisher_type_dict[row[0]] = Game_type.AAA\n",
    "\n",
    "# Add our own publisher list\n",
    "with open(\"our-aaa-publisher-list.csv\", 'r', encoding='utf8') as csvfile:\n",
    "    # creating a csv reader object\n",
    "    csvreader = csv.reader(csvfile)\n",
    " \n",
    "    # extracting each data row one by one\n",
    "    for row in csvreader:\n",
    "        publisher_type_dict[row[0]] = Game_type.AAA\n",
    "\n",
    "print(publisher_type_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63e1a94-b8a7-443b-91f8-209263ab596a",
   "metadata": {},
   "source": [
    "This list of publishers is a good place to start, although it couldn't hurt to find more lists to add.\n",
    "\n",
    "Next, apply this list of publishers to the database we're building. Only run the cell directly below this once or it will mess up the fields in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25341de3-3b21-469f-9d30-59df411aabe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "GAME_TYPE = 16\n",
    "\n",
    "original_fields.append(\"Game Type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb7120ca-fcd0-416d-80f4-1ba07d17a487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to parse TEAM string\n",
    "def parse_team_string(input):\n",
    "    # First remove the brackets\n",
    "    input = input[1:-1]\n",
    "    # Split into two if there are multiple teams mentioned\n",
    "    input = input.split(', ')\n",
    "    # Remove the beginning and ending apostraphes from each team\n",
    "    i = 0\n",
    "    while i < len(input):\n",
    "        input[i] = input[i][1:-1]\n",
    "        i += 1\n",
    "    return input\n",
    "\n",
    "# Go through every row in the database and tag it with AAA, INDIE, or UNKNOWN\n",
    "for row in original_rows:\n",
    "    team = parse_team_string(row[TEAM]) # this is a string which may list both the dev and pub, or only one\n",
    "    if row[PUBLISHER] != None:\n",
    "        team.append(row[PUBLISHER])\n",
    "\n",
    "    # Now team is a list from 1-3 of (possibly redundant) publishers. Run those publishers through the dict to classify the game\n",
    "    game_type = None\n",
    "    for pub in team:\n",
    "        if pub in publisher_type_dict:\n",
    "            game_type = publisher_type_dict[pub]\n",
    "        else:\n",
    "            game_type = Game_type.UNKNOWN\n",
    "        \n",
    "    row.append(game_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0145c63c-c0b9-4f53-bf5b-c4177fc10099",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "miHoYo\n",
      "Finji\n",
      "Square\n",
      "VU Games\n",
      "Sierra Entertainment\n",
      "THQ\n",
      "DotEmu\n",
      "id Software\n",
      "Psyonix\n",
      "Humble Bundle\n",
      "Humble Bundle\n",
      "Unknown\n",
      "Playdead\n",
      "Square\n",
      "Spike\n",
      "Square\n",
      "Square\n",
      "Motion Twin\n",
      "PopCap Games\n",
      "Focus Home Interactive\n",
      "Galactic Cafe\n",
      "Marvelous\n",
      "Unknown Worlds Entertainment\n",
      "Eidos Interactive\n",
      "Unknown\n",
      "Riot Games\n",
      "IO Interactive\n",
      "Unknown\n",
      "WSS playground\n",
      "Square EA\n",
      "Frictional Games\n",
      "Thunder Lotus Games\n",
      "Delightworks\n",
      "miHoYo\n",
      "Finji\n",
      "DotEmu\n",
      "Majesco\n",
      "id Software\n",
      "Psyonix\n",
      "Humble Bundle\n",
      "Humble Bundle\n",
      "Unknown\n",
      "Focus Home Interactive\n",
      "Galactic Cafe\n",
      "Marvelous\n",
      "Unknown Worlds Entertainment\n",
      "Eidos Interactive\n",
      "Unknown\n",
      "Riot Games\n",
      "The Behemoth\n",
      "Unknown\n",
      "IO Interactive\n",
      "Unknown\n",
      "WSS playground\n",
      "Sierra Entertainment\n",
      "Midway\n",
      "Subset Games\n",
      "Type-Moon\n",
      "Binary Haze Interactive\n",
      "Square EA\n",
      "Frictional Games\n",
      "Aksys Games\n",
      "Hi-Rez Studios\n",
      "Square-Enix\n",
      "Ignition Entertainment\n",
      "SNK\n",
      "Rare\n",
      "Microsoft\n",
      "THQ\n",
      "Unknown\n",
      "THQ\n",
      "Aqua Plus\n",
      "Eidos Interactive\n",
      "Neowiz Corporation\n",
      "Square\n",
      "Sierra Entertainment\n",
      "Deep Silver\n",
      "Square\n",
      "Eidos Interactive\n",
      "5pb\n",
      "Unknown\n",
      "Level 5\n",
      "Inti Creates\n",
      "Tecmo\n",
      "Double Fine Presents\n",
      "Agetec\n",
      "miHoYo\n",
      "Finji\n",
      "Gearbox Software\n",
      "Square\n",
      "THQ\n",
      "DotEmu\n",
      "Majesco\n",
      "id Software\n",
      "Psyonix\n",
      "Humble Bundle\n",
      "Humble Bundle\n",
      "Unknown\n",
      "Focus Home Interactive\n",
      "Gears for Breakfast\n",
      "Unknown\n",
      "Focus Home Interactive\n",
      "DECK13 Interactive GmbH\n",
      "Ember Lab\n",
      "Square\n",
      "Grasshopper Manufacture Inc.\n",
      "Thekla, Inc.\n",
      "THQ\n",
      "The PokÃ©mon Company\n",
      "Rebellion Games\n",
      "NIS America\n",
      "DECK13 Interactive GmbH\n",
      "Deep Silver\n",
      "Interplay\n",
      "Whiptail Interactive\n",
      "Trapdoor\n",
      "DotEmu\n",
      "GameMill Entertainment\n",
      "THQ\n",
      "Sold Out\n",
      "Interplay\n",
      "The Behemoth\n",
      "NIS America\n",
      "Square\n",
      "Eidos Interactive\n",
      "Tecmo\n",
      "Perfect World Entertainment\n",
      "Square\n",
      "5pb\n",
      "Unknown\n",
      "Level 5\n",
      "Inti Creates\n",
      "Tecmo\n",
      "Sierra Entertainment\n",
      "Epic Games\n",
      "CD Projekt\n",
      "Falcom Corporation\n",
      "Agetec\n",
      "Berserk Games\n",
      "Jackbox Games\n",
      "Origin Systems\n",
      "THQ\n",
      "Spike Co.\n",
      "MTV Games\n",
      "PopCap Games\n",
      "Williams Entertainment\n",
      "VU Games\n",
      "Xseed Games\n",
      "Rebellion Developments\n",
      "Grinding Gear Games\n",
      "DrinkBox Studios\n",
      "Microprose\n",
      "Eidos Interactive\n",
      "Gun Media\n",
      "Arena Entertainment\n",
      "GT Interactive\n",
      "Titus\n",
      "Media.Vision\n",
      "WayForward\n",
      "Jackbox Games\n",
      "Sony Online Entertainment\n",
      "THQ\n",
      "Jupiter Corporation\n",
      "Deep Silver\n",
      "U.S. Gold\n",
      "Telltale Games\n",
      "999\n"
     ]
    }
   ],
   "source": [
    "# Check how many classified games we have\n",
    "num_classified = 0\n",
    "for row in original_rows:\n",
    "    if row[GAME_TYPE] != Game_type.UNKNOWN:\n",
    "        num_classified += 1\n",
    "    else:\n",
    "        if row[PUBLISHER] != None:\n",
    "            # This will help us decide if there are any repeating publishers that we should try to classify\n",
    "            print(row[PUBLISHER])\n",
    "\n",
    "print(num_classified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "108016ce-0bf5-415e-9a91-28d8a9bcb8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the dataset by removing all unclassified games\n",
    "final_rows = []\n",
    "for row in original_rows:\n",
    "    if row[GAME_TYPE] != Game_type.UNKNOWN:\n",
    "        final_rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ea1db7c-99ac-49b1-8db7-42031cf26464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max genres per game: 6\n",
      "List of genres: ['Adventure', 'RPG', 'Brawler', 'Indie', 'Turn Based Strategy', 'Platform', 'Simulator', 'Puzzle', 'Shooter', 'Music', 'Strategy', 'Fighting', 'Arcade', 'Visual Novel', 'Tactical', 'Racing', 'Point-and-Click', 'Sport', 'Card & Board Game', 'Real Time Strategy', '']\n"
     ]
    }
   ],
   "source": [
    "# Helper function to parse GENRES string\n",
    "def parse_genres_string(input):\n",
    "    # First remove the brackets\n",
    "    input = input[1:-1]\n",
    "    # Split into multiple genres if there are multiple mentioned\n",
    "    input = input.split(', ')\n",
    "    # Remove the beginning and ending apostraphes from each genre\n",
    "    i = 0\n",
    "    while i < len(input):\n",
    "        input[i] = input[i][1:-1]\n",
    "        i += 1\n",
    "    return input\n",
    "\n",
    "# Gather info about genres. There are, at most, 6 genres per game. Most games have only 1-3 though\n",
    "# Append info to new columns for ease of using Altair later\n",
    "GENRE1 = 17\n",
    "GENRE2 = 18\n",
    "GENRE3 = 19\n",
    "GENRE4 = 20\n",
    "GENRE5 = 21\n",
    "GENRE6 = 22\n",
    "original_fields.append(\"Genre 1\")\n",
    "original_fields.append(\"Genre 2\")\n",
    "original_fields.append(\"Genre 3\")\n",
    "original_fields.append(\"Genre 4\")\n",
    "original_fields.append(\"Genre 5\")\n",
    "original_fields.append(\"Genre 6\")\n",
    "\n",
    "all_genres = []\n",
    "max_genres_per_game = 0\n",
    "for row in final_rows:\n",
    "    current_genres = parse_genres_string(row[GENRES])\n",
    "    \n",
    "    # Update max_genres_per_game if necessary\n",
    "    if len(current_genres) > max_genres_per_game:\n",
    "        max_genres_per_game = len(current_genres)\n",
    "\n",
    "    # Update list of all_genres if necessary\n",
    "    for genre in current_genres:\n",
    "        if genre not in all_genres:\n",
    "            all_genres.append(genre)\n",
    "\n",
    "    # Add genres to the row\n",
    "    i = 0\n",
    "    while i < 6:\n",
    "        if len(current_genres) > i:\n",
    "            # We have the i-th genre, so append it\n",
    "            row.append(current_genres[i])\n",
    "        else:\n",
    "            row.append(None)\n",
    "        i += 1\n",
    "    \n",
    "print(\"Max genres per game:\", max_genres_per_game)\n",
    "print(\"List of genres:\", all_genres)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9abc410c-c50e-41ad-be06-1ed97b14c786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no. of rows: 57951\n"
     ]
    }
   ],
   "source": [
    "# Add data on sales and console\n",
    "# Read in sales and console data\n",
    "sales_and_console_fields = []\n",
    "sales_and_console_rows = []\n",
    "sales_and_console_dict = {}    # store TITLE -> INDEX, so that we can quickly find the correct row for any given game.\n",
    "                               # We must use lists, because multiple games may be published under the same name (e.g. Tetris).\n",
    "\n",
    "# reading csv file\n",
    "with open(\"vgchartz-sales-and-consoles.csv\", 'r', encoding='Latin1') as csvfile:\n",
    "    # creating a csv reader object\n",
    "    csvreader = csv.reader(csvfile)\n",
    " \n",
    "    # extracting field names through first row\n",
    "    sales_and_console_fields = next(csvreader)\n",
    " \n",
    "    # extracting each data row one by one\n",
    "    index = 0\n",
    "    for row in csvreader:\n",
    "        sales_and_console_rows.append(row)\n",
    "        # Next, take care of the dictionary\n",
    "        if row[2] in sales_and_console_dict:    # Check the titles\n",
    "            # If there already is a value here, append the new value to the list\n",
    "            sales_and_console_dict[row[2]].append(index)\n",
    "        else:\n",
    "            # If there isn't a value here yet, create a list for the dictionary\n",
    "            sales_and_console_dict[row[2]] = [index]\n",
    "            \n",
    "        index += 1\n",
    " \n",
    "    # get total number of rows\n",
    "    print(\"Total no. of rows: %d\" % (csvreader.line_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68134645-16fc-4df0-9437-11ee05b55834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the correct data from sales and consoles to the rest of our \n",
    "# EDIT: for now, only consider consoles, not sales.  The sales data has been incredibly hard to come by\n",
    "\n",
    "import copy\n",
    "\n",
    "TOTAL_SALES = 23\n",
    "NA_SALES = 24\n",
    "JP_SALES = 25\n",
    "PAL_SALES = 26\n",
    "OTHER_SALES = 27\n",
    "CONSOLE = 28\n",
    "\n",
    "my_sales_fields = original_fields.copy()\n",
    "my_sales_rows = copy.deepcopy(final_rows)\n",
    "#for row in final_rows:\n",
    "#    my_sales_rows.append(final_rows.copy())\n",
    "#    print(row)\n",
    "\n",
    "my_sales_fields.append(\"Total Sales\")\n",
    "my_sales_fields.append(\"North American Sales\")\n",
    "my_sales_fields.append(\"Japan Sales\")\n",
    "my_sales_fields.append(\"PAL Sales\")\n",
    "my_sales_fields.append(\"Other Sales\")\n",
    "my_sales_fields.append(\"Console\")\n",
    "\n",
    "list_of_consoles = []\n",
    "\n",
    "for row in my_sales_rows:\n",
    "    # First, find the corresponding entry in sales and consoles\n",
    "    title = row[TITLE]\n",
    "    date = row[RELEASE_DATE]\n",
    "    true_year = date[-2:]    # in format e.g. \"17\" or \"23\"\n",
    "\n",
    "    # Check that it exists\n",
    "    if title in sales_and_console_dict:\n",
    "        # Once we get here, there is at least one entry in vgchartz for this title\n",
    "        possible_indices = sales_and_console_dict[title]\n",
    "        total_sales = None\n",
    "        na_sales = None\n",
    "        jp_sales = None\n",
    "        pal_sales = None\n",
    "        other_sales = None\n",
    "        console = []\n",
    "\n",
    "        # Pick out which of the possible indices is the correct one using the release date\n",
    "        true_index = possible_indices\n",
    "        found_info = False\n",
    "        for index in possible_indices:\n",
    "            possible_year = sales_and_console_rows[index][16][2:4]\n",
    "            current_console = sales_and_console_rows[index][3]\n",
    "\n",
    "            # If possible year is the same as true year, assume these are the same games. Check that this hit actually has the data we want, \n",
    "            # else ignore it because there are many repeat entries\n",
    "            if possible_year == true_year and current_console != None:\n",
    "                total_sales = sales_and_console_rows[index][11]\n",
    "                na_sales = sales_and_console_rows[index][12]\n",
    "                jp_sales = sales_and_console_rows[index][13]\n",
    "                pal_sales = sales_and_console_rows[index][14]\n",
    "                other_sales = sales_and_console_rows[index][15]\n",
    "                console.append(current_console)\n",
    "                #print(console)\n",
    "                #print(\"current console\", current_console)\n",
    "                found_info = True\n",
    "    \n",
    "        # Append the correct information as found from vgchartz\n",
    "        row.append(total_sales)\n",
    "        row.append(na_sales)\n",
    "        row.append(jp_sales)\n",
    "        row.append(pal_sales)\n",
    "        row.append(other_sales)\n",
    "        if found_info == True:\n",
    "            row.append(console)\n",
    "            #print(\"console:\", console)\n",
    "            #print(\"row[CONSOLE]:\", row[CONSOLE])\n",
    "            #print(\"row\", row)\n",
    "        else:\n",
    "            row.append(None)\n",
    "        \n",
    "    else:\n",
    "        # There was no entry in vgchartz for this title, so we have no data\n",
    "        row.append(None)    # TODO: this might not be the right syntax for an empty entry, double check this\n",
    "        row.append(None)\n",
    "        row.append(None)\n",
    "        row.append(None)\n",
    "        row.append(None)\n",
    "        row.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db09744d-202f-4280-ade7-c512576a38bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no. of cleaned rows: 693\n"
     ]
    }
   ],
   "source": [
    "# Finally, clean the dataset by removing rows from sales_final_rows if they don't have total sales data or console data\n",
    "final_sales_rows = []\n",
    "for row in my_sales_rows:\n",
    "    if row[CONSOLE] != None:\n",
    "        final_sales_rows.append(row)\n",
    "\n",
    "print(\"Total no. of cleaned rows:\", len(final_sales_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31234eb8-be55-45f2-ac96-2ce7c91d8cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to main CSV which will have data up to 2024\n",
    "with open('compiled_db.csv', 'w', encoding='utf8', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "\n",
    "    writer.writerow(original_fields)\n",
    "    writer.writerows(final_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b71faecb-6df3-41c8-aab1-950ecdea4a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to sales and console CSV which will only have data up to 2020\n",
    "with open('sales_compiled_db.csv', 'w', encoding='utf8', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "\n",
    "    writer.writerow(my_sales_fields)\n",
    "    writer.writerows(final_sales_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcde9e26-5b24-4b3a-adc4-5ec3cd7ad34d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
